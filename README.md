# DeepLearningAssignments

# Assignment 1

Part 1: Blackbox deep learning - Fast AI colab - https://github.com/fastai/fastbook/blob/master/01_intro.ipynb (Links to an external site.)
Write colab for SOTA using cnn_learner for image classification, unet_learner for segmentation, text_classifier_learner for sentiment analysis, tabular_learner for decisiontree, collab_learner for ranking, 

Part 2 : Whitebox deep learning - Read and perform the codelab https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist#0
 (Links to an external site.)
Part 3 : Showcase gradient descent in python colab from scratch without using any libraries - various versions of it - on linear regression problem
Submit thru github all the deliverables - create a directory assignment 1 and add these three colabs


# Assignment 2

Tensors are the bread and butter alphabet of deep learning. practicing and gaining good expertise on it is most important for success in deep learning.

 

a) Write a colab exploring various basic tensor operations including demonstrating einsum operations in tensorflow 2.0

Hint 1: https://www.tensorflow.org/guide/tensor (Links to an external site.)

Sample Colab : https://colab.sandbox.google.com/github/tensorflow/docs/blob/master/site/en/guide/tensor.ipynb (Links to an external site.)

https://colab.sandbox.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/customization/basics.ipynb (Links to an external site.)

 

https://colab.research.google.com/github/fastai/course-v3/blob/master/nbs/dl2/01_matmul.ipynb?authuser=1#scrollTo=kJ4qM9DxXNvb (Links to an external site.)

good video on einsum practice

https://www.youtube.com/watch?v=pkVwUVEHmfI

b) Write a colab exploring various basic tensor operations in pytorch

Presentation : https://docs.google.com/presentation/d/13Oo5gXwcsoq9oMC4XriAyxkvgicatBxfI4cZzDhRyiE/edit#slide=id.p (Links to an external site.)

Sample colab : https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/p1ch3/1_tensors.ipynb (Links to an external site.)

 

Please use your creativity (example https://github.com/google-research/tensorflow-coder/blob/master/UserJourneys.md (Links to an external site.))  and add more not so well used tensor operations - this is your best practice time for mastering operating on tensors which is fundamental to deep learning

 

Please publish a public github url of directory with these colabs 


# Assignment 3

All public github url directory with proper clean documentation and clean list of files and public access 

 

 Use 3 variables based non linear equation (the example i gave in class goes to  2 variables - https://docs.google.com/presentation/d/1rFtaPJZsB6E-k8g23-JzH2YylyS1b8NoCcD7zpPOK8U/edit#slide=id.gbb803640d1_0_452 (Links to an external site.) . Generate synthetic data using the equation you used and plot using 4d plot

a) Write  a colab  numpy only from scratch 3 layer deep neural network for non linear regression . Use proper non linear activation functions and proper number of hidden layer neurons - show the results / loss and epochs training and final output . You will be doing manual backprop and chain rule based gradient propagation 

Hint: 

https://colab.research.google.com/drive/1HS3qbHArkqFlImT2KnF5pcMCz7ueHNvY?usp=sharing&authuser=1#scrollTo=EGkS6nN6dQaz (Links to an external site.)

b) Write a colab pytorch from scratch - 3 layer deep neural network for non linear regression withotu using pytorch builtin layer functionality 

Hint https://docs.google.com/presentation/d/13Oo5gXwcsoq9oMC4XriAyxkvgicatBxfI4cZzDhRyiE/edit#slide=id.g826a355833_0_525 (Links to an external site.)

 

Hint: 

https://colab.research.google.com/drive/1HS3qbHArkqFlImT2KnF5pcMCz7ueHNvY?usp=sharing&authuser=1#scrollTo=EGkS6nN6dQaz (Links to an external site.)

 

c) Write  a colab pytorch classes based - 3 layer deep neural network for non linear regression using pytorch builtin functionality of modules etc.,. backprop etc.,.

d) Write  a colab  pytorch lightening version of the same

e) 

Tensorflow various variants low level, api, functional, model, builtin 

https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=KC5RgwGeBP-9 (Links to an external site.) 


eWrite  a colab  tensorflow only from scratch not using high level api  of the same

https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=KC5RgwGeBP-9 (Links to an external site.)

Write a colab tensorflow only with builtin layers of the same

https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=WavMVtXGQk-z (Links to an external site.)

 Write a colab with Use functional api high level api  of tensorflow for the same

https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?authuser=1#scrollTo=SyC7KfV-YcYS (Links to an external site.)


hint : https://colab.research.google.com/drive/169PfzM0kvtA5UP4k6Sl1yCG9tsE2MLia?authuser=1#scrollTo=C_2FyZeXjHd1 (Links to an external site.)

Write a colab with tensorflow only but using high level api


https://www.tutorialspoint.com/how-to-make-a-4d-plot-with-matplotlib-using-arbitrary-data


# Assignment 4

This assignment was locked Apr 14 at 11:59pm.
a) Do a codelab with all hyperparameters learning rate decay, dropout, batch norm

Hint :https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist?hl=en#0

Submit the colab in github repository

b) Do various experiments with weights and biases of hyperparameters in weights and biases 

of various optimizers, layer depth width, learning rate etc.,. both in keras and pytorch(2 colabs) - submit your executed colab and artifactslinks.

 

https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb (Links to an external site.)

https://docs.wandb.ai/guides/sweeps

Hint :

Keras:

https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases_keras.ipynb (Links to an external site.)

 

Pytorch : 

https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb (Links to an external site.)

c) Do keras  classifier for regression problem, image problem submit your colabs and artifacts links

follow all best practices like normalization etc,.,

Hint ; image : fashionmnist or pets , regression : california housing, 

 

Hint : https://github.com/ageron/handson-ml2/blob/master/10_neural_nets_with_keras.ipynb (Links to an external site.)

 

d) Write a colab to  Illustrate use of various activation functions, dropouts, learning rate schedulers , regularization techniques like gradient clipping, batch normalization, early stopping, l1 and l2 regularizations, optimizers on simple data set

Hint : https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb (Links to an external site.)


# Assignment 5

Note :  this is a long but most important assignment assignment - it helps you practice the various scenarios and advanced topics as well as practical ML applications on devices and browser very well. Please spend some time per week doing some portions of the assignments so you do not do it in last minute.

 

Part 1: 

A) Write a colab/colabs where you will use advanced Keras deep learning constructs concepts

This is a very important assignment - helps you understand and have an edge over others

Please ensure you use the links i provided for hints as examples. Use your own creativity. Properly annotate your colab/colabs appropriately and write proper explanation and description. Properly demonstrate each of these aspects with either individual colabs or one colab having all these. 

i) User custom learning rate scheduler (see https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb (Links to an external site.) onecyclescheduler example)

ii) use custom dropout - ( see MCAlphaDropout in above link)

iii) Use custom normalization - (see MaxNormDense in above link)

iv) use tensorboard - (see above link)

v) use custom loss function - (see HuberLoss in https://github.com/ageron/handson-ml2/blob/master/12_custom_models_and_training_with_tensorflow.ipynb (Links to an external site.)) 

vi) use custom activation function,initializer regularizer and kernel weight constraint (see leaky_relu, my_glorot_initializer, MyL1Regularizer , my_positive_weights in above link)

vii) use custom metric (see HuberMetric in above link)

viii) Use custom layers (see exponential_layer, MyDense, AddGaussianNoise, LayerNormalization in above link)

ix) Use custom model (see ResidualRegressor and ResidualBlock example in above link)

x) Custom optimizer (See MyMomentumOptimizer in above link)

xi) Custom Training Loop (see 13 section for fashion mnist in above link)

 

Part 2 : 

Do the below codelabs to exercise your ondevice ML skills

and in github provide all the artifacts and screenshots of your work (do not copy from codelab the screenshot - i would like to see it running on your computer screenshot )

a) Mobile App and Image training on device: Build and deploy a custom object detection model using tflite on android simulator (https://developers.google.com/codelabs/tflite-object-detection-android?hl=en#0 (Links to an external site.))

b) Mobile app and audio training on device : Build a custom pre-trained Audio Classification model (https://developers.google.com/codelabs/tflite-audio-classification-custom-model-android?hl=en#0 (Links to an external site.))

c) Web app and image training on device: TensorFlow.js Transfer Learning Image Classifier (https://codelabs.developers.google.com/codelabs/tensorflowjs-teachablemachine-codelab?hl=en#0 (Links to an external site.))

d) Webapp and audio training on device : TensorFlow.js - Audio recognition using transfer learning (https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab?hl=en#0 (Links to an external site.))

e) Using out of box sdk to do ML ondevice : Use ML Kit to perform Recognize text and facial features with ML Kit: Android (Links to an external site.), and Recognize, Identify Language and Translate text with ML Kit and CameraX: Android


# Assignment 6

Part 1 - supervised contrastive learning  - Using new loss 

Write a colab to demonstrate supervised contrastive learning loss based supervised classification versus regular softmax based one

Hint : Check colab links at https://docs.google.com/presentation/d/1UxtHDwjViC7VpSb0zB-kajGQ-TwznQmc-7LsbHRfO3s/edit#slide=id.gcdc5f16e5b_20_5 (Links to an external site.) and https://towardsdatascience.com/contrastive-loss-for-supervised-classification-224ae35692e7 (Links to an external site.) - Also check https://keras.io/examples/vision/supervised-contrastive-learning/ (Links to an external site.) 

Please provide necessary visualizations

Part 2 - Transfer learning on various modalities : 
Write simple colabs to transfer learn on images, videos, audios -  - with both as a feature extractor as well as a fine tuning usecases


Example hints : 

Audio : https://blog.tensorflow.org/2021/03/transfer-learning-for-audio-data-with-yamnet.html (Links to an external site.)

Video : https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub (Links to an external site.)

NLP : https://www.tensorflow.org/hub/tutorials/tf2_text_classification (Links to an external site.)  or https://amitness.com/2020/02/tensorflow-hub-for-transfer-learning/ (Links to an external site.) or pick 

Image :

Showcase basic transfer learning for a classification task (either cats/dogs or breeds of dogs) in a colab - with both as a feature extractor as well as a fine tuning usecase

Hint : https://www.tensorflow.org/tutorials/images/transfer_learning (Links to an external site.) or https://towardsdatascience.com/dog-breed-classification-using-cnns-and-transfer-learning-e36259b29925 (Links to an external site.)

or

use the below usecases : 

https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb (Links to an external site.)

https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb (Links to an external site.)

https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb


Part 3 - Zero shot transfer learning in colab

Showcase zero shot transfer learning with CLIP model 

Hint : https://towardsdatascience.com/how-to-try-clip-openais-zero-shot-image-classifier-439d75a34d6b (and associated colab) (Links to an external site.)

Showcase transfer learning using state of art models from tfhub (Eg: use bigtransfer for example) using tfhub

Hint : https://keras.io/examples/vision/bit/ (Links to an external site.) or flowers data set eg : https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub

# Assignment 7

Submit colabs for each of the below parts with proper run outputs in github directory (please put the link to github director) for assignment 7 

 

Part 1 : Sequence to sequence task : Demonstrate the use of RNN, LSTM, GRU, WAVENET  for a timeseries prediction task (next 10 items)  and show  it works better than regular classification

Hint : colab https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb  (Links to an external site.)and chapter 15 

 

Part 2: Demonstrate very simple many to one, one to many and many to many RNN colabs 

Hint : https://wandb.ai/ayush-thakur/dl-question-bank/reports/LSTM-RNN-in-Keras-Examples-of-One-to-Many-Many-to-One-Many-to-Many---VmlldzoyMDIzOTM

Part 3: Bidirectional RNN : Sequence to vector task : Demonstrate bidirectional RNN and all its features in sequential MNIST task classification colab

Hint : colab https://www.tensorflow.org/guide/keras/rnn  (Links to an external site.)

Part  4:  Practical application of RNN : Train a video action classifier using CNN-RNN combo (cnn for features and RNN for classification)

Hint : colab : https://keras.io/examples/vision/video_classification/ (Links to an external site.)

# Catchup 1
Write a deep recommender system system/colab which does both item to item, and user to item recommendation  models
which utilizes all the state of art techniques in one system
a) cnn, gru and bag of words models jointly for forming embeddings
b) dcn layer for  feature crossing
c) sequential model 
d) Deep recurrent networks for embeddings generation (uses multiple dens layers / non linearities before embedding)
e) deep ranking using list wise ranking 
f) scalable deep retrieval using scann
g) Multi task losses for multi objective loss (for both ranking and retrieval)
h) SNGP for out of box distribution of input example detection
i) Bandit algorithm for sampling multiple recommenders
j) tf-serving for serving and tfx for training 
All these are provided in colabs/setup in https://docs.google.com/presentation/d/1E4EqGILyfiRiWdtU1Enp0jhPPAJqnlrAYiiDyuaTqgQ/edit#slide=id.g122817339fb_0_598 (Links to an external site.)

Write a detailed read.me with all details and screenshots of running system

Note that this is an important assignment which utilizes all the skills you learnt (cnn, gru, embeddings etc.,.) in holistic single end2end application. i recommend folks who are not interested in marks also attempt this.

# Catch up 2

This assignment was locked May 23 at 11:59pm.
Write colab to demonstrate in graph neural networks using pytorch geometric using both GCN and GAT layers.
 

a) Graph Classification Problem

b) Edge Prediction Problem

c) Node Classification Problem

Hint :  https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html (Links to an external site.)  https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial7/GNN_overview.ipynb#scrollTo=49at-zVsjSXq (Links to an external site.)  and https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html (Links to an external site.) 

